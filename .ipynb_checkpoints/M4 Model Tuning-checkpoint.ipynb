{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To tune the model we have to modify the hyper parameters. Here is how to see the hyperparameter values for the svc function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\\n    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\\n    max_iter=-1, probability=False, random_state=None, shrinking=True,\\n    tol=0.001, verbose=False)\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "str(svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to search the best hyperparameter is to find it using grid search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=None, error_score=nan,\n",
      "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                              class_weight=None,\n",
      "                                              criterion='gini', max_depth=None,\n",
      "                                              max_features='auto',\n",
      "                                              max_leaf_nodes=None,\n",
      "                                              max_samples=None,\n",
      "                                              min_impurity_decrease=0.0,\n",
      "                                              min_impurity_split=None,\n",
      "                                              min_samples_leaf=1,\n",
      "                                              min_samples_split=2,\n",
      "                                              min_weight_fraction_leaf=0.0,\n",
      "                                              n_estimators=100, n_jobs=None,\n",
      "                                              oob_score=False,\n",
      "                                              random_state=None, verbose=0,\n",
      "                                              warm_start=False),\n",
      "             iid='deprecated', n_jobs=None,\n",
      "             param_grid={'n_estimators': array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26,\n",
      "       27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43,\n",
      "       44, 45, 46, 47, 48, 49, 50])},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
      "             scoring=None, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_grid = {'n_estimators': np.arange(10, 51)}\n",
    "\n",
    "clf_cv = GridSearchCV(RandomForestClassifier(), param_grid)\n",
    "\n",
    "clf_cv.fit(X, y)\n",
    "\n",
    "clf_cv.best_params_\n",
    "\n",
    "#{'n_estimators': 42}\n",
    "\n",
    "clf_cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multiple Hyperparametrization**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the hyperparameter grid\n",
    "param_grid = {\"max_depth\": [3, None],\n",
    "              \"max_features\": [1, 3, 10],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Randomized Search**\n",
    "\n",
    "As the hyperparameter grid gets larger, grid search becomes slower. In order to solve this problem, instead of trying out every single combination of values, we could randomly jump around the grid and try different combinations. There's a small possibility we may miss the best combination, but we would save a lot of time, or be able to tune more hyperparameters in the same amount of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RandomizedSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Create the hyperparameter grid\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": randint(1, 11),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# Call RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(clf, param_dist)\n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(X, y)\n",
    "\n",
    "# Print best parameters\n",
    "print(random_search.best_params_)\n",
    "\n",
    "#{'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 10}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance\n",
    "\n",
    "- Scores representing how much each feature contributes to a prediction\n",
    "- Effective way to communicate results to stakeholders\n",
    "    - Which features ra important drivers of churn\n",
    "    - Which features can be removed from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier()\n",
    "\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "random_forest.feature_importances_\n",
    "\n",
    "# Sort importances\n",
    "sorted_index = np.argsort(importances)\n",
    "\n",
    "# Create labels\n",
    "labels = X.columns[sorted_index]\n",
    "\n",
    "# Clear current plot\n",
    "plt.clf()\n",
    "\n",
    "# Create plot\n",
    "plt.barh(range(X.shape[1]), importances[sorted_index], tick_label=labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding new Features\n",
    "\n",
    "Adding new features can help to improve the model. Let's see an example\n",
    "\n",
    "Let's consider that for the Dataset the following features were added:\n",
    "- Region_Code\n",
    "- Cost_Call\n",
    "- Total_Charge\n",
    "- Total_Minutes\n",
    "- Total_Calls\n",
    "- Min_Call\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# Instantiate the classifier\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Fit to the data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Print the accuracy\n",
    "print(clf.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
